---
title: "Assignment2"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Tasks

**Note**:

• Dataset is imbalanced.
• Features are categorical (Nominal, Ordinal, Binary) and numerical.
• Missing imputation does not seem to be needed in your pipeline.
• Use nominal and ordinal polytomous models.
• Propose a hierarchical logit approach to predict right, center and left wing voting in the
political spectrum.

## Data Preparation

**Univariate Descriptive Analysis (to be included for each variable) [Eliya]:**

• Original numeric variables corresponding to qualitative concepts are present then they
have to be converted to factors.
• Original numeric variables corresponding to real quantitative concepts are kept as numeric
but additional factors should also be created as a discretization of each numeric variable.
• Exploratory Data Analysis for each variable (numeric summary and graphic support).

**Data Quality Report [Achraf]:**
Per variable, count:
• Number of missing values
• Number of errors (including inconsistencies)
• Number of outliers
• Rank variables according the sum of missing values (and errors).
Per individuals, count:
• number of missing values
• number of errors,
• number of outliers
• Identify individuals considered as multivariant outliers.

Create variable adding the total number missing values, outliers and errors. Describe these
variables, to which other variables exist higher associations.
• Compute the correlation with all other variables. Rank these variables according the
correlation
• Compute for every group of individuals (group of age, size of town, singles, married, ...) the
mean of missing/outliers/errors values. Rank the groups according the computed mean.

**Profiling [Eliya]:**
• Polytomous Target: 6 parties
• Polytomous Target: right/center/left orientation.

ROSE package for balancing data

## Modeling

-   Train and test split

-   (use set.seed(your birthday))

```{=html}
<!-- -->
```
-   Model reasonable factors as numeric variables also using transformations if needed.

-   Grouping levels in factors is allowed.

-   Adding factor main effects to the best model containing numeric variables

-   Adding factor main effects and interactions (limit your statement to order 2) to the best
    model containing numeric variables.

-   Goodness of fit and Model Interpretation for each proposal (nominal/ordinal).

-   Goodness of fit and Model Interpretation for political orientation (right/center/left). Make
    your own allocation of political parties to the right/center/left wing orientation.

```{r}
# Clear plots
if(!is.null(dev.list())) dev.off()
# Clean workspace
rm(list=ls())
```

First, we turn qualitative,nominal and ordinal variables into factors. When it's east/west or gender we trun it into a factor with the actual name.

We can see the summary and nothing too suspicious when look at the data. We can see CDU/CSU party gets most votes on our sample, majority of voters are open for immigration (around 3,4,5), most voters are from the east of Germany, most voters have a plus average intrest in the elections, most voters income is relativity high because we can see that the variable (before being a factor) has a mean and median around 3 and as a factor we see 582 with income 3.
In addition, no nulls or blanks in the data. From the boxplot we can see that income and east/west have points outside the box but we know why is it.
When ploting the data we don't see anything suspicious 
When define political orientation we see most voters are center, then left and the less is right, we can see that 2/3 of the voters are voting for the center parties.
```{r}
data("gles", package = "MNLpred")
df <- gles
summary(gles)
df$vote <- factor(df$vote)
df$egoposition_immigration <- factor(df$egoposition_immigration)
df$f.ostwest <- factor(df$ostwest, labels = c("west","east"))
df$political_interest <- factor(df$political_interest)
df$income <- factor(df$income)
df$f.gender <- factor(df$gender,labels = c("male","female"))
summary(df)
library(car)
boxplot(df[,c(1:2,4:5,7:8)])
plot(df[,c(1:2,4:5,7:8)])

is.null(df) #no nulls in the data
which(df=="") #no blanks found in the data
round(prop.table(summary(df$vote)),2)

df$f.vote <- ''
df[which(df$vote=="AfD"),9] <- "right"
df[which(df$vote=="CDU/CSU"),9] <- "center"
df[which(df$vote=="FDP"),9] <- "center"
df[which(df$vote=="Gruene"),9] <- "left"
df[which(df$vote=="LINKE"),9] <- "left"
df[which(df$vote=="SPD"),9] <- "center"

df$f.vote <-factor(df$f.vote)
summary(df)
round(prop.table(summary(df$f.vote)),2)
library(GGally)
ggpairs(df[,c(1:2,4:5,7:8,9)])
```

Profile and Feature Selection - we are going to look at two target variables, vote and f.vote
*f.vote:*
When we analysis the categorical variables we see voters for center parties are most significant when immigration policy is 5 so quite in the middle between open to not. Most of them are from the east part while voters from the west part are least significant. We can also see the income=4 is significant so more stable financially voters are for the center parties.
Left parties voters are characterized with open views on immigration, both male and female and high income.
Right parties are mostly against immigration, they don't have much interest in politics, mostly male voters and quite low income voters.
*vote*
We can see that for almost all parties the most significant value is immigration views. There is only one right party in the data so the inferring is like the above. CDU/CSU voters immigration openness have a wide spectrum (lowest is 1 and highest is 7). income = 2 so quite in the middle at that aspect. FDP is most significant for immigration while it can be 6, 0 or 2. Gruene is most significant for immigration 2, mostly female voters with quite high political interest. LINKE voters significantly when they from the west part of Germany and open for immigration policy. SPD voters are significant to have openness for immigration and low political interest.
```{r}
library(FactoMineR)
res.cat_f.vote <- catdes(df[,c(2,4,5,7:9)],num.var=6);res.cat_f.vote

res.cat_vote <- catdes(df[,c(1,2,4,5,7,8)],num.var=1);res.cat_vote

```


```{r}
set.seed(1310)
t <- sample(1:nrow(df),round(0.66*nrow(df),0)) # rows for training
train <- df[t,]  # working/training set
test <- df[-t,]  # testing set
col(train)
m0 <- multinom(f.vote ~ 1, data = train) #we start from the null model
summary(m0)
#we do not have numerical quantitative variable and since all of the rest are based on numerical nominal variables we will use all of them
m1 <- multinom(f.vote ~ egoposition_immigration+political_interest+income, data = train)
summary(m1)
#perform step for the best model so far
m2 <- step(m1)
summary(m2) #best model so far has D() of 906.63 and AIC 950.63
anova(m1,m2) #we cannot reject the null hypothesis and the models are equivalent so it is better for us the small model when we already know it's significant that they are equivalent
m3 <- multinom(f.vote ~ egoposition_immigration*f.ostwest + egoposition_immigration+f.ostwest + egoposition_immigration*f.gender + egoposition_immigration+f.gender, data = train) #adding interactions and additive of the factors
summary(m3)
m4 <- step(m3)
summary(m4) #best model so far we got f.vote ~ egoposition_immigration + f.ostwest + f.gender
#results are Deviance = 890.39 AIC = 942.39
#since we don't have order between left center right we use multinom() and not polr()
#FOR US ONLY - I think since we don't have numerical quantitative variable we don't have use for 2nd or 3rd order, I think there is a way to check whether or not we need it.
```
