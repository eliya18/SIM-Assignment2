---
title: "Assignment2"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Tasks

**Note**:

• Dataset is imbalanced. • Features are categorical (Nominal, Ordinal, Binary) and numerical. • Missing imputation does not seem to be needed in your pipeline. • Use nominal and ordinal polytomous models. • Propose a hierarchical logit approach to predict right, center and left wing voting in the political spectrum.

## Data Preparation

**Univariate Descriptive Analysis (to be included for each variable) [Eliya]:**

• Original numeric variables corresponding to qualitative concepts are present then they have to be converted to factors. • Original numeric variables corresponding to real quantitative concepts are kept as numeric but additional factors should also be created as a discretization of each numeric variable. • Exploratory Data Analysis for each variable (numeric summary and graphic support).

**Data Quality Report [Achraf]:** Per variable, count: • Number of missing values • Number of errors (including inconsistencies) • Number of outliers • Rank variables according the sum of missing values (and errors). Per individuals, count: • number of missing values • number of errors, • number of outliers • Identify individuals considered as multivariant outliers.

Create variable adding the total number missing values, outliers and errors. Describe these variables, to which other variables exist higher associations. • Compute the correlation with all other variables. Rank these variables according the correlation • Compute for every group of individuals (group of age, size of town, singles, married, ...) the mean of missing/outliers/errors values. Rank the groups according the computed mean.

**Profiling [Eliya]:** • Polytomous Target: 6 parties • Polytomous Target: right/center/left orientation.

ROSE package for balancing data

## Modeling

-   Train and test split

-   (use set.seed(your birthday))

-   Model reasonable factors as numeric variables also using transformations if needed.

-   Grouping levels in factors is allowed.

-   Adding factor main effects to the best model containing numeric variables

-   Adding factor main effects and interactions (limit your statement to order 2) to the best model containing numeric variables.

-   Goodness of fit and Model Interpretation for each proposal (nominal/ordinal).

-   Goodness of fit and Model Interpretation for political orientation (right/center/left). Make your own allocation of political parties to the right/center/left wing orientation.

```{r}
# Clear plots
if(!is.null(dev.list())) dev.off()
# Clean workspace
rm(list=ls())
```

# Load Data

```{r}

#load libraries
library("nnet")

#load data
data("gles", package = "MNLpred")
df <- gles
summary(df)
```

We can see the summary and nothing too suspicious when look at the data. In addition, no nulls or blanks in the data.

# Preprocessing

## Formatting

```{r}
sapply(df, class)
```

We have a lot of categorical variables which have a numerical type. For a better understanding it will be converted to factor taking into account metadata.

```{r}
# Transform variables to factors
#df$vote <- factor(df$vote)
#df$egoposition_immigration <- factor(df$egoposition_immigration, ordered = TRUE)
#df$ostwest <- factor(ifelse(df$ostwest==0,"No","Yes"))
#df$political_interest <- factor(df$political_interest, ordered=TRUE)
#df$income <- factor(df$income, ordered=TRUE)
#df$gender <- factor(ifelse(df$gender==0,"Male","Female"))

df$vote <- factor(df$vote)
df$egoposition_immigration <- factor(df$egoposition_immigration)
df$f.ostwest <- factor(df$ostwest, labels = c("west","east"))
df$political_interest <- factor(df$political_interest)
df$income <- factor(df$income)
df$f.gender <- factor(df$gender,labels = c("male","female"))
summary(df)

#round(prop.table(summary(df$vote)),2)
```

Now we can understand better the data and we can see that we that we have a balance in gender. Also the majority of people is from Eastern Germany.

Now let's try to find errors and inconsistencies in format

```{r}
which(df=="") #no blanks found in the data

sapply(df, unique) # Check unique values for each attribute

sum(duplicated(df))

head(df[duplicated(df),])

df$error = 0
number_of_errors_per_attribute = c(rep(0, 6));number_of_errors_per_attribute

summary(df)

```

Taking into account metadata, no errors where found in the data since all values are in the specification.

## Outliers

Since data is all categorical there is no way to detect outliers. However, we will label the lest frequent categories as outliers.

### Univariate

Let's see the frequency of each level in each attribute

```{r}


#attributes_report  <- data.frame(attributes = c(names(df)))

#summary(attributes_report)

#names(attributes_report)

number_of_outliers_per_attribute = c()

df$outlier = 0

# vote
prop.table(table(df$vote))
df[which(df$vote == "AfD"),"outlier"] <- 1
number_of_outliers_per_attribute <- append(number_of_outliers_per_attribute, length(which(df$vote == "AfD")))

 # egoposition_immigration
prop.table(table(df$egoposition_immigration))
df[which(df$egoposition_immigration == 8),"outlier"] <- 1
number_of_outliers_per_attribute <- append(number_of_outliers_per_attribute, length(which(df$egoposition_immigration == 8)))

#ostwest
prop.table(table(df$f.ostwest))
number_of_outliers_per_attribute <- append(number_of_outliers_per_attribute, 0)

# political_interest
prop.table(table(df$political_interest))
df[which(df$political_interest == 0),"outlier"] <- 1
number_of_outliers_per_attribute <- append(number_of_outliers_per_attribute, length(which(df$political_interest == 0)))

# income
prop.table(table(df$income))
df[which(df$income == 0),"outlier"] <- 1
number_of_outliers_per_attribute <- append(number_of_outliers_per_attribute, length(which(df$income == 0)))

# gender
prop.table(table(df$f.gender))
#df[which(df$political_interest == 0),"outlier"] <- 1
number_of_outliers_per_attribute <- append(number_of_outliers_per_attribute,0)


str(number_of_outliers_per_attribute)
```

Outliers won't be removed. However, it's important to keep in mind those classes that are a minority in case in further iterations levels are grouped to improve the model.

### Multivariate

Detecting multivariate outliers it's not an easy process since all data is factors and we can't apply methods like mahalanobis distance. One solution could be using MCA which is a factorial method (TODO)

```{r}
 #sapply(gles, class)
```

```{r}
#library(chemometrics)
#res.out<-Moutlier(gles[,c(2,3,4,5,6)],quantile=0.975)

#str(res.out)
#res.out$cutoff
## [1] 4.297305
#which((res.out$md > res.out$cutoff) & (res.out$rd > res.out$cutoff))
## 1048
## 1045
#plot( res.out$md, res.out$rd )
#abline(h=res.out$cutoff, col="red")
#abline(v=res.out$cutoff, col="red")
```

## Missing data

There is no missing data so no imputation is needed.

```{r}
is.null(df) #no nulls in the data
number_of_na_per_attribute = c(rep(0, 6));number_of_na_per_attribute
df$na = 0
```

## Data quality report

Let's create the report for each attribute and per individual takining into account the results obtained in the different processes.

```{r}
# per variabe
attributes_report  <- data.frame(attributes = c(names(df[,c(1:6)])), errors=number_of_errors_per_attribute, outliers=number_of_outliers_per_attribute, na=number_of_na_per_attribute)

print(attributes_report)

# per individual

individuals_report = df[,c("error","outlier", "na")]
print(individuals_report)

```

Let's compute the correlation of variables in terms of errors

```{r}

attributes_report$total <- attributes_report$error +  attributes_report$outlier + attributes_report$na
attributes_report = attributes_report[order(attributes_report$total,decreasing = TRUE),]
print(attributes_report)


```

Finally let's check the most problematic individuals

```{r}

individuals_report$total = individuals_report$error + individuals_report$outlier + individuals_report$na
individuals_report = individuals_report[order(individuals_report$total,decreasing = TRUE),]

print(individuals_report)
```

As we can see in general, data quality is pretty good. The only thing it might need is to group some levels in further iterations

```{r}
summary(df)
df <- df[,c(1:8)] # Remove attributes that are used for the report

```

# Univariate Descriptive Analysis

```{r}
summary(df)
```

First, we turn qualitative,nominal and ordinal variables into factors. When it's east/west or gender we trun it into a factor with the actual name.

We can see the summary and nothing too suspicious when look at the data. We can see CDU/CSU party gets most votes on our sample, majority of voters are open for immigration (around 3,4,5), most voters are from the east of Germany, most voters have a plus average intrest in the elections, most voters income is relativity high because we can see that the variable (before being a factor) has a mean and median around 3 and as a factor we see 582 with income 3. In addition, no nulls or blanks in the data. From the boxplot we can see that income and east/west have points outside the box but we know why is it. When ploting the data we don't see anything suspicious When define political orientation we see most voters are center, then left and the less is right, we can see that 2/3 of the voters are voting for the center parties.

```{r}
library(car)
boxplot(df[,c(1:2,4:5,7:8)])
plot(df[,c(1:2,4:5,7:8)])

round(prop.table(summary(df$vote)),2)

df$f.vote <- ''
df[which(df$vote=="AfD"),9] <- "right"
df[which(df$vote=="CDU/CSU"),9] <- "center"
df[which(df$vote=="FDP"),9] <- "center"
df[which(df$vote=="Gruene"),9] <- "left"
df[which(df$vote=="LINKE"),9] <- "left"
df[which(df$vote=="SPD"),9] <- "center"

df$f.vote <-factor(df$f.vote)
summary(df)
round(prop.table(summary(df$f.vote)),2)
library(GGally)
ggpairs(df[,c(1:2,4:5,7:8,9)])
```

Profile and Feature Selection - we are going to look at two target variables, vote and f.vote *f.vote:* When we analysis the categorical variables we see voters for center parties are most significant when immigration policy is 5 so quite in the middle between open to not. Most of them are from the east part while voters from the west part are least significant. We can also see the income=4 is significant so more stable financially voters are for the center parties. Left parties voters are characterized with open views on immigration, both male and female and high income. Right parties are mostly against immigration, they don't have much interest in politics, mostly male voters and quite low income voters. *vote* We can see that for almost all parties the most significant value is immigration views. There is only one right party in the data so the inferring is like the above. CDU/CSU voters immigration openness have a wide spectrum (lowest is 1 and highest is 7). income = 2 so quite in the middle at that aspect. FDP is most significant for immigration while it can be 6, 0 or 2. Gruene is most significant for immigration 2, mostly female voters with quite high political interest. LINKE voters significantly when they from the west part of Germany and open for immigration policy. SPD voters are significant to have openness for immigration and low political interest.

```{r}
library(FactoMineR)
res.cat_f.vote <- catdes(df[,c(2,4,5,7:9)],num.var=6);res.cat_f.vote

res.cat_vote <- catdes(df[,c(1,2,4,5,7,8)],num.var=1);res.cat_vote

```

# Modeling

## Nominal proposal

### Train test split

```{r}
set.seed(1310)

t <- sample(1:nrow(df),round(0.66*nrow(df),0)) # rows for training
train <- df[t,]  # working/training set
test <- df[-t,]  # testing set
col(train)
summary(train)
```

### Baseline model

```{r}
m0 <- multinom(vote ~ 1, data = train) #we start from the null model
summary(m0)
#we do not have numerical quantitative variable and since all of the rest are based on numerical nominal variables we will use all of them
m1 <- multinom(vote ~ egoposition_immigration+political_interest+income, data = train)
summary(m1)
#perform step for the best model so far
m2 <- step(m1)
summary(m2) #best model so far has D() of 906.63 and AIC 950.63
anova(m1,m2) #we cannot reject the null hypothesis and the models are equivalent so it is better for us the small model when we already know it's significant that they are equivalent
```

### Improving the model

```{r}
m3 <- multinom(vote ~ egoposition_immigration*f.ostwest + egoposition_immigration+f.ostwest + egoposition_immigration*f.gender + egoposition_immigration+f.gender, data = train) #adding interactions and additive of the factors
summary(m3)
m4 <- step(m3)
summary(m4) 
#best model so far we got f.vote ~ egoposition_immigration + f.ostwest + f.gender
#results are Deviance = 890.39 AIC = 942.39
#since we don't have order between left center right we use multinom() and not polr()
#FOR US ONLY - I think since we don't have numerical quantitative variable we don't have use for 2nd or 3rd order, I think there is a way to check whether or not we need it.
#FOR US ONLY - we can also try to turn the immigration number into a range where 0-3, 4-7, 8-10 are open, mild, restrictive respectively - BUT I guess if we do that we should do it from the beginning where also the test data will appear like that otherwise we won't be able to compare the results under predict()

```


Model with target variable vote only
```{r}
library(nnet)
set.seed(1310)
t <- sample(1:nrow(df),round(0.66*nrow(df),0)) # rows for training
train <- df[t,]  # working/training set
test <- df[-t,]  # testing set
col(train)
summary(train)
m0 <- multinom(vote ~ 1, data = train) #we start from the null model
summary(m0) #very high AIC and Deviance
m1 <- multinom(vote ~ egoposition_immigration+political_interest+income, data = train) #model with numerical qualitative variables
summary(m1) #improve from the null model
anova(m1,m0) #nested models with p_value 0 so we reject the null hypothesis and say models are not equivalent 
AIC(m1,m0)
#we can see m1 has better AIC and Deviance
m2 <- step(m1)
summary(m2)
anova(m2,m1) #we cannot reject the null hypothesis so it's statistically significant to say models are equivalent
AIC(m2,m1) #m2 has a lower AIC but m1 has lower deviance
m3 <- multinom(vote ~ egoposition_immigration*f.ostwest + egoposition_immigration+f.ostwest + egoposition_immigration*f.gender + egoposition_immigration+f.gender, data = train) #adding factors
summary(m3)
m4 <- step(m3)
summary(m4)
anova(m4,m3,m2)
AIC(m4,m3,m2) #we can see that m3 has the lowest AIC, however m2 has the lowest deviance and m2 and m4 are not equivalent
BIC(m4,m3,m2) #THIS ONE I DON'T KNOW IF TO LEAVE IN OR NOT, I THOUGHT MAYBE IT CAN SOLVED OUR AIC Deviance CONTRIDICTION
#we are going with the lowest AIC so m4 is best model so far.

```

Model with target variable f.vote only
```{r}
set.seed(1310)
t <- sample(1:nrow(df),round(0.66*nrow(df),0)) # rows for training
train <- df[t,]  # working/training set
test <- df[-t,]  # testing set
col(train)
summary(train)
mm0 <- multinom(f.vote ~ 1, data = train) #we start from the null model
summary(mm0)
#we do not have numerical quantitative variable and since all of the rest are based on numerical nominal variables we will use all of them
mm1 <- multinom(f.vote ~ egoposition_immigration+political_interest+income, data = train)
summary(mm1)
#perform step for the best model so far
mm2 <- step(mm1)
summary(mm2) #best model so far has D() of 906.63 and AIC 950.63
anova(mm1,mm2) #we cannot reject the null hypothesis and the models are equivalent so it is better for us the small model when we already know it's significant that they are equivalent
mm3 <- multinom(f.vote ~ egoposition_immigration*f.ostwest + egoposition_immigration+f.ostwest + egoposition_immigration*f.gender + egoposition_immigration+f.gender, data = train) #adding interactions and additive of the factors
summary(mm3)
mm4 <- step(mm3)
summary(mm4) #best model so far we got f.vote ~ egoposition_immigration + f.ostwest + f.gender
#results are Deviance = 890.39 AIC = 942.39
#since we don't have order between left center right we use multinom() and not polr()
#FOR US ONLY - I think since we don't have numerical quantitative variable we don't have use for 2nd or 3rd order, I think there is a way to check whether or not we need it.
#FOR US ONLY - we can also try to turn the immigration number into a range where 0-3, 4-7, 8-10 are open, mild, restrictive respectively - BUT I guess if we do that we should do it from the beginning where also the test data will appear like that otherwise we won't be able to compare the results under predict()
anova(mm4,mm3)
#what should we do when 2 models which one has low AIC but higher deviance compare to the other model (as we see between m3 and m4)

```

Adding 3 levels of immigration policies to see if it will improve the current results we have.
```{r}
df$f.pos_imm <- ""
df$f.pos_imm <- ifelse(df$egoposition_immigration %in% c(0,1,2,3),"open",ifelse(df$egoposition_immigration %in% c(4,5,6,7),"mild","restrictive"))
set.seed(1310)
t <- sample(1:nrow(df),round(0.66*nrow(df),0)) # rows for training
train <- df[t,]  # working/training set
test <- df[-t,]  # testing set
m5 <- multinom(f.vote ~ f.pos_imm*f.ostwest + f.pos_imm+f.ostwest + f.pos_imm*f.gender + f.pos_imm+f.gender, data = train)
summary(m5)
m6 <- step(m5)
summary(m6)
```

### Goodness of fit and model interpretation

**Goodness of fit**

```{r}

m4$deviance;m4$edf;2*nrow(df)-m4$edf
1-pchisq(m4$deviance, 2*nrow(df)-m4$edf)
```

For the best model obtained which include egoposition_immigration, f.ostwest and f.gender has a p value of 0.3514997. This means that we fail to reject H0 where the model is consistent to data so we conclude by saying model fit's well the data.

**Model interpretation**

Since egoposition_immigration has many levels, we will interpret the effect of f.ostweseast and f.genderfaemale.

```{r}
coef(m4)
#f.ostwesteast
summary(m4)
coef(m4)[,12]
exp(coef(m4)[,12])
100*(exp(coef(m4)[,12])-1)

#f.genderfemale
coef(m4)[13]
exp(coef(m4)[,13])
100*(exp(coef(m4)[,13])-1)
```

The log odds of being in from the east of germany will increase by 0.826 fior CDU/CSU, 0.825 for FDP, 0.824for Gruene, 0.07 for LINKE, 0.67 fSPD. The increasce is similar for three of the candidates and then we can see that SPD is following by not that far. Finally LINKE seems the least increased by people from the east of Germany

Being a female we can see different outcomes where there is also an increase of 1.21 for CDU/CSU, 1.30 for FDP, 1.72for Gruene, 1.15 for LINKE and 1.35 for SPD. In this case, all have a similar increase. However, Gruene is the one being the most benefited of that level.

With the egopositional_immigration there are a lot of levels but we can summarize by saying that levels 1 and 2 have an increase around 22 of the log odds in the two first levels. Then the rest of the levels (3-10) are decreascing the log odds with some levels more variable than others but we can see that the majority of values reside between 10-15.

**Prediction of probabilities**

Let's try different combinations of parameters of each to try to asses the prediction probabilities for each party

```{r}
# p
summary(df$egoposition_immigration)
# neutral immigration, from west and male
predict(m4, type="probs", newdata=data.frame(egoposition_immigration=factor(5), f.ostwest = factor("west"), f.gender=factor("male")))

# neutral immigration, from west and female
predict(m4, type="probs", newdata=data.frame(egoposition_immigration=factor(5), f.ostwest = factor("west"), f.gender=factor("female")))

# neutral immigration, from east and male
predict(m4, type="probs", newdata=data.frame(egoposition_immigration=factor(5), f.ostwest = factor("east"), f.gender=factor("male")))

# neutral immigration, from east and female
predict(m4, type="probs", newdata=data.frame(egoposition_immigration=factor(5), f.ostwest = factor("east"), f.gender=factor("female")))


```

From this results we obtained that males and females from east and west with a neutral egoposition_immigration are more likely to vote for CDU/CSU and then SPD. So this means that gender and being from the west are not big factors in the predictibility of the model.

**TODO**: Group levels to better explain the variability of predictions depending of egoposition_immigration.

**Predictive power**

Let's check the predictive power of the model using both train and test data and find the performance metrics of the model.

On train

```{r}

tt<-table(predict(m4),train$vote);tt #Checks that the model i not predicting part times

tt
100*sum(diag(tt))/sum(tt) # ACCURACY of the model


```

On test

```{r}
tt<-table(predict(m4, newdata = test),test$f.vote);tt #Checks that the model i not predicting part times
100*sum(diag(tt))/sum(tt) # ACCURACY of the model


predicted <- predict(m4, newdata = test);predicted
actual <- test$vote; actual


library(caret)

confusionMatrix(predicted, actual, mode = "everything")
```

We get an accuracy of 32% which is not a great result.

## Ordinal proposal

### Train test split

### Baseline model

### Improving the model

### Goodness of fit and model interpretation

## 

```{r}



exp(coef(m4))

```

```{r}


ggplot(data = train, aes(x =  egoposition_immigration, 
                                  y = f.vote)) +
  geom_line() + # Mean
  #facet_wrap(.~ c.use, ncol = 3) + #, scales = "free_y"
  #scale_y_continuous() + # % labels
  #scale_x_continuous() +
  theme_bw() +
  labs(y = "Observed logodds",
       x = "egoposition_immigration") # Always label your axes ;)
```

## Herarchical proposal
